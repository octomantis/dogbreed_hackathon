{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dog breed classification using Pytorch Estimators on Azure Machine Learning service\n",
    "\n",
    "Have you ever seen a dog and not been able to tell the breed? Some dogs look so similar, that it can be nearly impossible to tell. For instance these are a few breeds that are difficult to tell apart:\n",
    "\n",
    "#### Alaskan Malamutes vs Siberian Huskies\n",
    "![Image of Alaskan Malamute vs Siberian Husky](http://cdn.akc.org/content/article-body-image/malamutehusky.jpg)\n",
    "\n",
    "#### Whippet vs Italian Greyhound \n",
    "![Image of Whippet vs Italian Greyhound](http://cdn.akc.org/content/article-body-image/whippetitalian.jpg)\n",
    "\n",
    "There are sites like http://what-dog.net, which use Microsoft Cognitive Services to be able to make this easier. \n",
    "\n",
    "In this tutorial, you will learn how to train a Pytorch image classification model using transfer learning with the Azure Machine Learning service. The Azure Machine Learning python SDK's [PyTorch estimator](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-pytorch) enables you to easily submit PyTorch training jobs for both single-node and distributed runs on Azure compute. The model is trained to classify dog breeds using the [Stanford Dog dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/) and it is based on a pretrained ResNet18 model. This ResNet18 model has been built using images and annotation from ImageNet. The Stanford Dog dataset contains 120 classes (i.e. dog breeds), to save time however, for most of the tutorial, we will only use a subset of this dataset which includes only 10 dog breeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "\n",
    "### Conda/Miniconda\n",
    "[Download](https://conda.io/miniconda.html) and install Miniconda. Select the Python 3.7 version or later. Don't select the Python 2.x version.\n",
    "\n",
    "### Create Conda Environment\n",
    "\n",
    "Start with the conda environment definition file:\n",
    "\n",
    "```\n",
    "name: learnai-hackathon\n",
    "\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "\n",
    "  - pip:\n",
    "    - azureml-sdk[notebooks,contrib]\n",
    "    - https://download.pytorch.org/whl/cu90/torch-1.0.0-cp36-cp36m-win_amd64.whl\n",
    "    - torchvision\n",
    "\n",
    "```\n",
    "\n",
    "*Note*: The above instructions are for windows. If you are using a different OS, you may need to replace the last two lines above with something else, following [these](https://pytorch.org/) (section `Quick Start Locally`) instructions.\n",
    "\n",
    "Add the following *conda* dependencies for advanced jupyter notebook features (such as widgets): `ipywidgets`, `nb_conda`.\n",
    "\n",
    "Add the following *pip* dependencies for deep learning: `scikit-image`, `tensorflow`.\n",
    "\n",
    "Once you are done editing the file, create the conda environment.\n",
    "\n",
    "\n",
    "### Install jupyter notebook extensions for widgetes\n",
    "\n",
    "Run the following installation steps on the command line (e.g. Anaconda Shell)\n",
    "\n",
    "Install the Python SDK:  make sure to install notebook, and contrib\n",
    "``` \n",
    "jupyter nbextension install --py --user azureml.widgets\n",
    "jupyter nbextension enable azureml.widgets --user --py\n",
    "```\n",
    "\n",
    "\n",
    "### Start Jupyter Notebook server\n",
    "Change directory into the folder of our repository, activate the above conda environment, and type `jupyter notebook` to start the jupyter server. \n",
    "\n",
    "\n",
    "### Test whether SDK was installed correctly in your conda environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.8\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an image classification model?\n",
    "Training machine learning models, particularly deep neural networks, is often a time- and compute-intensive task. Once you've finished writing your training script and running on a small subset of data on your local machine, you will likely want to scale up your workload.\n",
    "\n",
    "To facilitate training, the Azure Machine Learning Python SDK provides a high-level abstraction, the estimator class, which allows users to easily train their models in the Azure ecosystem. You can create and use an Estimator object to submit any training code you want to run on remote compute, whether it's a single-node run or distributed training across a GPU cluster. For PyTorch and TensorFlow jobs, Azure Machine Learning also provides respective custom PyTorch and TensorFlow estimators to simplify using these frameworks.\n",
    "\n",
    "### Steps to train with a Pytorch Estimator:\n",
    "In this tutorial, we will:\n",
    "- Connect to an Azure Machine Learning service Workspace \n",
    "- Create a remote compute target\n",
    "- Download your training data (Optional)\n",
    "- Create your training script\n",
    "- Create an Estimator object\n",
    "- Submit your training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create workspace\n",
    "\n",
    "In the next step, you will create your own Workspace to use in this tutorial.\n",
    "\n",
    "**You will be asked to login during this step. Please use your Microsoft AAD credentials.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to update the following 2 values based on the sub we are using\n",
    "subscription_id = '...'                           # <<please retrieve from URL at above paragraph>>\n",
    "workspace_name = '...'                            # <<a Unique Name -- use your alias>>\n",
    "location = '...'\n",
    "resource_group = '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a workspace, as we have before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "\n",
    "ws = '...'\n",
    "\n",
    "ws.write_config()\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a few minutes, so let's talk about what a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) is while it is being created.\n",
    "![](aml-workspace.png)\n",
    "\n",
    "\n",
    "## Create a remote compute target\n",
    "For this tutorial, we will create an AML Compute cluster as we have before, using a `Standard_NC6` VM, which include P100 GPUs for deep learning, as the [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) to execute your training script on. \n",
    "\n",
    "**Creation of the cluster takes approximately 5 minutes** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"...\"\n",
    "\n",
    "try:\n",
    "    # todo\n",
    "    print('Found existing compute target.')\n",
    "except KeyError:\n",
    "    print('Creating a new compute target...')\n",
    "    # todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can ask for the provisioning state to see whether the cluster is up already of if there were errors\n",
    "compute_target.status.serialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach the blobstore with the training data to the workspace\n",
    "While the cluster is still creating, let's attach some data to our workspace.\n",
    "\n",
    "The dataset we will use consists of ~150 images per class. Some breeds have more, while others have less. Each class has about 100 training images each for dog breeds, with ~50 validation images for each class. \n",
    "\n",
    "Two datasets are available.  The first smaller dataset with only 10 dog breeds we will use for developing our approach. The second full dataset contains 120 dog breeds.  This dataset is very large, so let's ignore it for now. \n",
    "\n",
    "(optional) Download these two datasets as zip files and look at a couple of them to become familiar with what your model will be asked to accomplish.\n",
    "- [10 breeds](https://github.com/heatherbshapiro/pycon-canada/blob/master/breeds-10.zip?raw=true)\n",
    "- [120 breeds](https://github.com/heatherbshapiro/pycon-canada/blob/master/breeds.zip?raw=true)\n",
    "\n",
    "To make the data accessible for remote training, you will need to keep the data in the cloud. AML provides a convenient way to do so via a [Datastore](https://docs.microsoft.com/azure/machine-learning/service/how-to-access-data). The datastore provides a mechanism for you to upload/download data, and interact with it from your remote compute targets. It is an abstraction over Azure Storage. The datastore can reference either an Azure Blob container or Azure file share as the underlying storage. \n",
    "\n",
    "We already put these data into blob for you. Just ask for us for the account name to fill in below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name='breeds', \n",
    "                                             container_name='dogbreeds',\n",
    "                                             account_name='...', \n",
    "                                             account_key='uzFqBxsdDHPlxrM1hc4vdFpJrkEU/E7af+dybu4iVLm4FQEMIhscxOR+/tWXAIr23qLRaEpkVSAIELTCR/Rnjw==')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload your train and test data to blob storage\n",
    "\n",
    "We already uploaded the data, so you don't need to do this again. We are leaving this here, in case you want to use a different dataset sometime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.upload(\"breeds-10\")\n",
    "# ds.upload(\"breeds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a reference to the path on the datastore with the training data. We can do so using the `path` method. In the next section, we can then pass this reference to our training script's `--data_dir` argument. We will start with the 10 classes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_on_datastore = 'breeds-10'\n",
    "ds_data = ds.path(path_on_datastore)\n",
    "print(\"Data store reference: \" + ds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Data\n",
    "\n",
    "If you are interested in downloading the data locally, you can run `ds.download(\".\", 'breeds-10')`. This might take several minutes and not necessary whatsover for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds.download('.', 'breeds-10', show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training script\n",
    "Now you will need to create your training script. In this tutorial, the training script is already provided for you at `pytorch_train_orig.py`. But you still need to make modifications to it, so that it properly logs results in Azure. We recommend that you leave the above `_orig.py` script in place, and make a copy of it at `pytorch_trian.py`.\n",
    "\n",
    "However, if you would like to use AML's [tracking and metrics](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#metrics) capabilities, you will have to add a small amount of AML code inside your training script. \n",
    "\n",
    "In `pytorch_train.py`, we will log some metrics to our AML run. To do so, we will access the AML run object within the script:\n",
    "\n",
    "```Python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "\n",
    "Further within the method `fixed_feature_model` in `pytorch_train.py`, we log the learning rate and momentum parameters, the number of classes in the model:\n",
    "\n",
    "```Python\n",
    "    run.log('lr', np.float(learning_rate))\n",
    "    run.log('momentum', np.float(momentum))\n",
    "    run.log('num_classes', num_classes)\n",
    "```\n",
    "\n",
    "This might be a good opportunity to investigate the order of execution of the various methods in this script.\n",
    "\n",
    "We also need to log the best validation accuracy (`best_acc`) the model achieves in `train_model`:\n",
    "```Python\n",
    "            # log the best val accuracy to AML run\n",
    "            if phase == 'val': \n",
    "                run.log('best_val_acc', np.float(best_acc))\n",
    "```\n",
    "\n",
    "If you downloaded the data, you can start to train the model locally (note that it will take long if you don't have a GPU -- 21 min. on a Core i7 CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir outputs\n",
    "!python pytorch_train.py --data_dir breeds-10 --num_epochs 1 --output_dir outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on the remote compute\n",
    "Now that you have your data and training script prepared, you are ready to train on your remote compute cluster. You can take advantage of Azure compute to leverage GPUs to cut down your training time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this transfer learning PyTorch tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from #todo import #todo\n",
    "\n",
    "experiment_name = 'pytorch-dogs'\n",
    "#todo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a PyTorch estimator\n",
    "The AML SDK's PyTorch estimator enables you to easily submit PyTorch training jobs for both single-node and distributed runs. For more information on the PyTorch estimator, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-train-pytorch). The following code will define a single-node PyTorch job.\n",
    "\n",
    "There are two things you need to do here. \n",
    "1. Look into the file `pytorch_train.py` and determine which `script_params` you need to specify.\n",
    "1. Specify the compute_target on which you want to train your model.\n",
    "\n",
    "The `script_params` parameter is a dictionary containing the command-line arguments to your training script `entry_script`. Please note the following:\n",
    "- We pass our training data reference `ds_data` to our script's `--data_dir` argument. This will 1) mount our datastore on the remote compute and 2) provide the path to the training data `breeds` on our datastore.\n",
    "- We specified the output directory as `./outputs`. The `outputs` directory is specially treated by AML in that all the content in this directory gets uploaded to your workspace as part of your run history. The files written to this directory are therefore accessible even once your remote run is over. In this tutorial, we will save our trained model to this output directory.\n",
    "- We recommend that you train for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##BATCH AI\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    # todo, looks at the file pytorch_train.py, and determine \n",
    "    # which script_params you need to specify.\n",
    "}\n",
    "\n",
    "estimator10 = PyTorch(source_directory='.', \n",
    "                    script_params=script_params,\n",
    "                    compute_target=#todo, \n",
    "                    entry_script='pytorch_train.py',\n",
    "                    pip_packages=['tensorboardX'],\n",
    "                    use_gpu=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To leverage the Azure VM's GPU for training, we set `use_gpu=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor your run\n",
    "You can monitor the progress of the run with a Jupyter widget (class `RunDetails` of module `azureml.widgets`). Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens during a run?\n",
    "If you are running this for the first time, the compute target will need to pull the docker image, which will take about 2 minutes. This gives us the time to go over how a **Run** is executed in Azure Machine Learning. \n",
    "\n",
    "Note: had we not created the workspace with an existing ACR, we would have also had to wait for the image creation to be performed -- that takes and extra 10-20 minutes for big GPU images like this one. This is a one-time cost for a given python configuration, and subsequent runs will then be faster. We are working on ways to make this image creation faster.\n",
    "\n",
    "![](aml-run.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tensorboard\n",
    "Tensorboard is a popular Deep Learning Training visualization tool. It is part of TensorFlow framework, but can be used from PyTorch as well by using TensorboadX python package. TensorboardX allows PyTorch to write metrics and log information in Tensorboard format.\n",
    "\n",
    "In `pytorch_train.py`, we will log metrics to \"magical\" `logs` directory. The content of this special directory is automatically streamed by Azue ML service. The logging into Tensorboard event format is performed by SummaryWriter object im the `main` method:\n",
    "\n",
    "```Python\n",
    "    from tensorboardX import SummaryWriter\n",
    "    writer = SummaryWriter(f'./logs/{run.id}')\n",
    "```\n",
    "\n",
    "Within the script (method `train_model`) we write more detailed mini-batch loss and accuracy:\n",
    "```Python\n",
    "                writer.add_scalar(f'{phase}/Loss', loss.item(), niter)\n",
    "                writer.add_scalar(f'{phase}/Accuracy', (corrects / inputs.size(0)).item(), niter)\n",
    "```\n",
    "\n",
    "We also log the epoch level accuracy to Tensorboard:\n",
    "```Python\n",
    "            writer.add_scalar(f'{phase}/Epoch_accuracy', epoch_acc, (epoch+1) * len(dataloaders[phase]))\n",
    "```\n",
    "\n",
    "Finally, to ensure that TensorboardX python package is installed in Python environment during the training run, we add it using pip_packages parameter of the Estimator object:\n",
    "```Python\n",
    "estimator = PyTorch(...\n",
    "                    pip_packages=['tensorboardX']\n",
    "                    ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing and launching Tensorboard\n",
    "Azure ML SDK provides built-in integration with Tensorboard in package `azureml-contrib-tensorboard`, installed as part of the contrib extras package in prerequisites. In addition, you will need to pip install tensorboard, which we also did as part of the prerequisites.\n",
    "\n",
    "Edit your `environment.yml` file, to also include that package (, `tensorboardX`), and update your conda environment (`conda env update -f environment.yml`).\n",
    "\n",
    "While the run is in progress (or after it has completed), we just need to start Tensorboard with the run as its target, and it will begin streaming logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.tensorboard import Tensorboard\n",
    "\n",
    "# The Tensorboard constructor takes an array of runs, so be sure and pass it in as a single-element array here\n",
    "tb = Tensorboard([run10])\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()\n",
    "print(\"Click on the http link printed below to access your Tensorboard!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Tensorboard\n",
    "\n",
    "When you're done, make sure to call the `stop()` method of the Tensorboard object, or it will stay running even after your job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Try a different optimizer\n",
    "\n",
    "The script uses a standard stochastic gradient (SGD) optimizer for optimizing weights in the neural network.  This might now be the best option.  Go to the torch [documentation](https://pytorch.org/docs/stable/optim.html) and see what other optimizers are available.  For example, you could try the `Adam` optimizer to see whether your model learns faster or achieves better validation accuracy with that.\n",
    "\n",
    "### (optional) Try a different architecture\n",
    "\n",
    "If you take a close look at pytorch_train.py, you will notice that it uses a pretrained ResNet18 architecture.  You could try a different one, and see whether that improves your performance.\n",
    "\n",
    "### (optional) Try training the model from scratch\n",
    "\n",
    "Whatever architecture you decide on, consider training it from scratch.\n",
    "\n",
    "### (optional) Try different kinds of pre-processing\n",
    "\n",
    "Check out the load_data method in `pytorch_train.py`. You will noticed that there are a couple of sequential preprocessing steps. Think about playing with those, maybe there are better ways to preprocess your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning\n",
    "\n",
    "Now that the setup is working, we can go to the full dataset with 120 classes. We just need to point to a different path on the datastore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = ds.path('breeds')\n",
    "print(full_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the script_params.  We recommend training for 25 `epochs`. Make sure to set the `mode` to `fine_tune` ([see fast.ai wiki](http://wiki.fast.ai/index.php/Fine_tuning)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AML Compute\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    # ... \n",
    "}\n",
    "\n",
    "estimator120 = PyTorch(source_directory='.', \n",
    "                        script_params=script_params,\n",
    "                        compute_target=compute_target, \n",
    "                        entry_script='pytorch_train.py',\n",
    "                        pip_packages=['tensorboardX'],\n",
    "                        node_count=1,\n",
    "                        use_gpu=True)\n",
    "\n",
    "run120 = experiment.submit(estimator120)\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run120).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Distributed Training with Horovod\n",
    "\n",
    "But now training takes very long (1.5 hours), so let's see if we can run this job on multiple GPUs to cut down on training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's cancel the above job\n",
    "run120.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the model on multiple nodes is simple (in this case using Horovod MPI-based algorithm running on 4 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AML Compute\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    # you can use the same params as above\n",
    "}\n",
    "\n",
    "estimator120 = PyTorch(source_directory='.', \n",
    "                        script_params=script_params,\n",
    "                        compute_target=compute_target, \n",
    "                        pip_packages=['tensorboardX'],\n",
    "                        entry_script='pytorch_train_horovod.py',\n",
    "                        node_count=4,\n",
    "                        distributed_backend='mpi',\n",
    "                        use_gpu=True)\n",
    "\n",
    "run120 = experiment.submit(estimator120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run120).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.tensorboard import Tensorboard\n",
    "\n",
    "# The Tensorboard constructor takes an array of runs, so be sure and pass it in as a single-element array here\n",
    "tb = Tensorboard([run120])\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on 4 nodes completes in about 10 minutes and achieves 76% accuracy, which is similar to accuracy produced by single node training. This is great improvement of training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    " Now that you have trained an initial model, you can tune the hyperparameters of this model to optimize model performance. Azure ML allows you to automate this tuning, in an efficient manner via early termination of poorly performing runs.\n",
    "\n",
    "You can configure your Hyperparamter Tuning experiment by specifying the following info -\n",
    "- Define the hyparparameter space - specify ranges, distribution and sampling\n",
    "- Early Termination policy\n",
    "- Optimization metric\n",
    "- Resource / Compute budget\n",
    "- Desired concurrency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        # todo \n",
    "        # todo \n",
    "    }\n",
    ")\n",
    "\n",
    "policy = BanditPolicy() #todo\n",
    "\n",
    "\n",
    "hdc = HyperDriveRunConfig(estimator=estimator10, \n",
    "                          hyperparameter_sampling=ps, \n",
    "                          policy=policy, \n",
    "                          primary_metric_name=#todo,\n",
    "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                          max_total_runs=50,\n",
    "                          max_concurrent_runs=4)\n",
    "\n",
    "hd_run = experiment.submit(hdc)\n",
    "RunDetails(hd_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the jobs is running, take a look at the [Hyperdrive documentation](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive?view=azure-ml-py) to see what other options Hyperdrive offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at any time, you can pull out the metrics generated so far from the runs\n",
    "hd_run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report your results\n",
    "\n",
    "What is the best score if have a achieved and want to share with the group? \n",
    "What do you think were the most important changes that allowed you to get there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing\n",
    "### Create scoring script\n",
    "\n",
    "First, we will create a scoring script that will be invoked by the web service call. Note that the scoring script must have two required functions:\n",
    "* `init()`: In this function, you typically load the model into a `global` object. This function is executed only once when the Docker container is started. \n",
    "* `run(input_data)`: In this function, the model is used to predict a value based on the input data. The input and output typically use JSON as serialization and deserialization format, but you are not limited to that.\n",
    "\n",
    "Refer to the scoring script `pytorch_score.py` for this tutorial. Our web service will use this file to predict the dog breed based on a 120 class model trained earlier, located in the folder `model`. We will test the scoring file locally first before you go and deploy the web service.\n",
    "\n",
    "1. Import the scoring script, so that init() and run() are accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pytorch_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Call the init function -- this will load the model and the class_names from the model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_score.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Add some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, base64\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import io, requests\n",
    "\n",
    "##Get random dog\n",
    "def get_random_dog():\n",
    "    r = requests.get(url =\"https://dog.ceo/api/breeds/image/random\")\n",
    "    URL= r.json()['message']\n",
    "    return URL\n",
    "\n",
    "def imgToBase64(img):\n",
    "    \"\"\"Convert pillow image to base64-encoded image\"\"\"\n",
    "    imgio = BytesIO()\n",
    "    img.save(imgio, 'JPEG')\n",
    "    img_str = base64.b64encode(imgio.getvalue())\n",
    "    return img_str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find an image of a dog and call the run() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get Random Dog Image\n",
    "URL = get_random_dog()\n",
    "\n",
    "with urllib.request.urlopen(URL) as url:\n",
    "    test_img = io.BytesIO(url.read())\n",
    "\n",
    "\n",
    "plt.imshow(Image.open(test_img))\n",
    "\n",
    "base64Img = imgToBase64(Image.open(test_img))\n",
    "\n",
    "result = pytorch_score.run(input_data=json.dumps({'data': base64Img}))\n",
    "print(URL)\n",
    "print(json.loads(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model\n",
    "Once the run completes, we can register the model that was created.\n",
    "\n",
    "**Please use a unique name for the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "model = Model.register(ws, model_name='model', model_path = 'model', description='120 Dogbreeds')\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Deploy model as web service\n",
    "Once you have your trained model, you can deploy the model on Azure. You can deploy your trained model as a web service on Azure Container Instances (ACI), Azure Kubernetes Service (AKS), IoT edge device, or field programmable gate arrays (FPGAs)\n",
    "\n",
    "ACI is generally cheaper than AKS and can be set up in 4-6 lines of code. ACI is the perfect option for testing deployments. Later, when you're ready to use your models and web services for high-scale, production usage, you can deploy them to AKS.\n",
    "\n",
    "\n",
    "In this tutorial, we will deploy the model as a web service in [Azure Container Instances](https://docs.microsoft.com/en-us/azure/container-instances/) (ACI). \n",
    "\n",
    "\n",
    "For more information on deploying models using Azure ML, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create environment file\n",
    "Then, we will need to create an environment file (`myenv.yml`) that specifies all of the scoring script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image by AML. In this case, we need to specify `torch`, `torchvision`, `pillow`, and `azureml-sdk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile myenv.yml\n",
    "name: myenv\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - pip:\n",
    "    - torch\n",
    "    - torchvision\n",
    "    - pillow\n",
    "    - azureml-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the container image\n",
    "Now configure the Docker image that you will use to build your ACI container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script='pytorch_score.py', \n",
    "                                                  runtime='python', \n",
    "                                                  conda_file='myenv.yml',\n",
    "                                                  description='Image with dog breed model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the ACI container\n",
    "We are almost ready to deploy. Create a deployment configuration file to specify the number of CPUs and gigabytes of RAM needed for your ACI container. While it depends on your model, the default of `1` core and `1` gigabyte of RAM is usually sufficient for many models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={'data': 'dog_breeds',  'method':'transfer learning', 'framework':'pytorch'},\n",
    "                                               description='Classify dog breeds using transfer learning with PyTorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the registered model\n",
    "Finally, let's deploy a web service from our registered model. First, retrieve the model from your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = ws.models['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, deploy the web service using the ACI config and image config files created in the previous steps. We pass the `model` object in a list to the `models` parameter. If you would like to deploy more than one registered model, append the additional models to this list.\n",
    "\n",
    "**Please use a unique service name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service_name = 'dog120'\n",
    "service = Webservice.deploy_from_model(workspace=ws,\n",
    "                                       name=service_name,\n",
    "                                       models=[model],\n",
    "                                       image_config=image_config,\n",
    "                                       deployment_config=aciconfig,)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your deployment fails for any reason and you need to redeploy, make sure to delete the service before you do so: `service.delete()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip: If something goes wrong with the deployment, the first thing to look at is the logs from the service by running the following command:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "service.get_logs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the web service\n",
    "Finally, let's test our deployed web service. We will send the data as a JSON string to the web service hosted in ACI and use the SDK's `run` API to invoke the service. Here we will take an arbitrary image from online to predict on. This is the same as above, but now we are testing on our own trained model. You can use any dog image, but please remember we only trained on 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Get Random Dog Image\n",
    "URL = get_random_dog()\n",
    "\n",
    "with urllib.request.urlopen(URL) as url:\n",
    "    test_img = io.BytesIO(url.read())\n",
    "\n",
    "plt.imshow(Image.open(test_img))\n",
    "\n",
    "with urllib.request.urlopen(URL) as url:\n",
    "    test_img = io.BytesIO(url.read())\n",
    "\n",
    "plt.imshow(Image.open(test_img))\n",
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def imgToBase64(img):\n",
    "    \"\"\"Convert pillow image to base64-encoded image\"\"\"\n",
    "    imgio = BytesIO()\n",
    "    img.save(imgio, 'JPEG')\n",
    "    img_str = base64.b64encode(imgio.getvalue())\n",
    "    return img_str.decode('utf-8')\n",
    "\n",
    "base64Img = imgToBase64(Image.open(test_img))\n",
    "\n",
    "result = service.run(input_data=json.dumps({'data': base64Img}))\n",
    "print(json.loads(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete web service\n",
    "Once you no longer need the web service, you should delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
